[{"chunk_id": "rag_overview_0000_79443336", "doc_id": "rag_overview", "content": "Retrieval-Augmented Generation (RAG) is an AI framework that combines \n        information retrieval with text generation. It enhances large language \n        models by providing them with relevant context from external knowledge \n        sources.\n        \n        RAG works by first retrieving relevant documents based on a query, \n        then using those documents as context for generating a response. \n        This approach helps reduce hallucinations and provides more accurate, \n        up-to-date information.\n        \n        Key components of RAG include:\n        1. Document chunking and storage\n        2. Vector embeddings for semantic search\n        3. Retrieval mechanisms (dense, sparse, or hybrid)\n        4. Language model for response generation\n        \n        Popular embedding models include sentence-transformers like \n        all-MiniLM-L6-v2 for fast inference, or larger models like \n        all-mpnet-base-v2 for better quality.", "metadata": {"char_count": 956, "word_count": 108}}, {"chunk_id": "faiss_intro_0000_f68a376b", "doc_id": "faiss_intro", "content": "FAISS (Facebook AI Similarity Search) is a library for efficient \n        similarity search of dense vectors. It supports various index types\n        including flat indexes, IVF indexes, and HNSW for different \n        performance/accuracy tradeoffs.\n        \n        FAISS is particularly useful for RAG systems because it can handle\n        millions of vectors with fast query times.", "metadata": {"char_count": 385, "word_count": 49}}]